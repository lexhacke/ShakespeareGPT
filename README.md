ShakespeareGPT —  A lightweight GPT-style model built from scratch with Tensorflow

✒️ Rundown

Transformer-based architecture using multi-head self-attention with key-value residual connections (inspired by Vaswani et al., 2017) for token-level sequence modeling—trained on a small corpus of shakespearean literature.

📁 Files 

LLM-v3.ipynb — LLM training loop & sampling

LLM_v3_modeltest.ipynb — loading of shakespeareGPT.keras and subsequent usage

*shakespeareGPT.keras — model weights ⚠️700+ MB I can't directly upload this to Github: https://drive.google.com/file/d/1yuCVThGyAL9ft3LKA3BcxRrdwUJLdiIR/view?usp=sharing

shakespeare.txt — small training corpus

